# ТЗ: Система учёта скважин и парсинга отчётов

**Краткое описание:**
Сервис для управления информацией по скважинам: организации, проекты (месторождения), скважины, этапы работ и события с привязкой к файлам (отчёты за сутки, журналы). Возможность загружать Excel/PDF, парсить их (настраиваемые шаблоны) с помощью LLM/парсера и сохранять извлечённые данные как события/снапшоты. Отображение в календаре/таймлайне, просмотр истории и фильтрация.

---

## Цели системы
- Централизовать историю работ по каждой скважине и этапу.
- Позволить инженерам загружать ежедневные отчёты и автоматически извлекать ключевые данные в структурированном виде.
- Дать возможность совместной работы (организации, приглашения пользователей, права доступа).
- MVP без LLM — ручной импорт и базовый парсинг; более поздние версии — LLM/ML-парсинг и векторное хранилище.

---

## Акторы и роли
- **Owner** — создатель организации, полный доступ.
- **Admin** — управляет организацией, проектами и пользователями.
- **Engineer / Editor** — создаёт и редактирует скважины, этапы, события, загружает файлы и шаблоны парсинга.
- **Viewer** — просмотр данных, календаря и файлов.

---

## Основные сущности (высокоуровнево)
- **Organization**: название, адрес, список пользователей, настройки (шаблоны парсинга доступные для организации).
- **Project (Field)**: принадлежит организации; географические метки; список скважин.
- **Well (скважина)**: идентификатор, местоположение, метаданные, связанные этапы, файлы.
- **Stage (этап)**: произвольное название, начало/конец, порядок, принадлежность к скважине.
- **Event (событие)**: тип (мигновенное или период), время/интервал, описание, привязанные файлы, автор, создаётся вручную или автоматически (например, загрузкой файла).
- **File**: оригинальное имя, тип (xls/xlsx/csv/pdf/other), размер, дата загрузки, связанные сущности (скважина, этап, событие), статус парсинга, результаты парсинга.
- **ParserTemplate**: шаблон для извлечения данных из Excel (mapping колонок, правила преобразования, регулярки, пример), может быть привязан к организации/проекту/скважине.
- **ParsedSnapshot**: структурированные данные, извлечённые из файла (например: глубина, расход, время, параметры), привязанные к событию(ям).

---

## Функциональные требования (MVP + расширения)

### MVP (обязательно для первой версии)
1. Аутентификация (email/password) + приглашения по email.
2. Организации и роль-based доступ.
3. CRUD для проектов, скважин, этапов, событий.
4. Загрузка файлов (S3) с привязкой к скважине/этапу/событию.
5. Просмотр списка файлов по скважине/этапу/датам.
6. Календарный/таймлайн-вид (день/неделя/месяц) с отображением этапов и событий (аналог Google Calendar).
7. При загрузке файла — автоматическое создание события «Файл загружен» (робот).
8. Ручной парсинг: пользователь выбирает одном столбец/диапазон в xlsx и мэпит к полям события (базовый CSV/XLSX парсер).
9. Полный лог изменений (audit) и историю событий по скважине.

### Версия +1 (парсинг и шаблоны)
1. Модуль шаблонов для Excel: можно создать шаблон (пример, правила сопоставления колонок именам полей), повторно применять при загрузке.
2. Автоматический парсинг файлов при загрузке по применяемым шаблонам.
3. Создание событий/снапшотов из результатов парсинга (вставляются в хронологию).
4. UI для тестирования шаблона на примере файла (preview вывод).

### Версия +2 (LLM / ML интеграция)
1. Интеграция LLM (опционально локальный/облачный): преобразование сложных таблиц/печатных pdf/нестандартных форм в структурированные данные.
2. Векторное хранилище (для поиска по семантике и агентов) — опция (Pinecone / Elastic + kNN / Milvus / локальная реализация).
3. Интерфейс для обучения/ускоренного улучшения шаблонов на основе фидбека.
4. Автоматическое предложение шаблона при загрузке нового формата (на основе похожих файлов).

---

## Нефункциональные требования
- Масштабируемость: поддержка сотен организаций, тысяч скважин и миллионов событий.
- Производительность: список событий за сутки — отклик < 200 ms (по возможности кэшировать).
- Безопасность: RBAC, HTTPS, S3-ACLs, шифрование по требованию.
- Доступность: SLA для MVP — внутреннее тестирование, затем 99.5%.
- Логи и мониторинг: CloudWatch/Prometheus + алерты.

---

## Предложенная архитектура и стэк (рекомендация)
**Frontend:** Next.js (React) или Nuxt (Vue) — на выбор; компоненты: календарь/таймлайн (react-big-calendar / fullcalendar), файловый менеджер, редактор шаблонов.

**Backend:** Serverless (AWS Lambda + API Gateway) или контейнеры (ECS/Fargate). Node.js / NestJS или Python (FastAPI) — привычно для команды.

**Storage & DB:**
- Файлы: S3 (хуки при загрузке -> Lambda для обработок).
- Metadata: MongoDB (Atlas) или DynamoDB — гибкая схема для событий и шаблонов.
- Индексация/поиск: ElasticSearch/OpenSearch для быстрых запросов и timeline.
- Vector DB (опционально): Pinecone / Milvus / Elastic vector

**Parsing / LLM:**
- Базовый парсер: XLSX, CSV (xlsx library), PDF: pdfminer / tabula / camelot.
- LLM integration: через API (OpenAI, Anthropic, Claude) либо локально размещённые модели.
- Orchestrator: Step function / Queue (SQS) для фонового парсинга и обработки.

**Инфраструктура:** Terraform / CDK для IaC. CI/CD: GitHub Actions.

---

## API (примерный набор эндпоинтов)
- `POST /api/orgs` — создать организацию
- `GET /api/orgs/{id}` — детали
- `POST /api/orgs/{id}/invite` — пригласить пользователя
- `POST /api/projects` — создать проект
- `POST /api/wells` — создать скважину
- `POST /api/wells/{id}/stages` — создать этап
- `POST /api/wells/{id}/events` — создать событие
- `POST /api/files/upload` — загружает файл (возвращает presigned URL или direct)
- `GET /api/wells/{id}/files` — список файлов
- `POST /api/parsers/templates` — CRUD шаблонов
- `POST /api/parsers/parse` — запустить парсинг файла вручную

---

## UX / UI — ключевые экраны и поведение
1. Дашборд организации — проекты, активные скважины, недавние файлы и события.
2. Project/Field view — карта мини-карты и список скважин.
3. Well view — метаданные, этапы, timeline; панель файлов справа.
4. Editor события — быстрый create (точечное) / период.
5. Файловый менеджер — фильтры по дате, этапу, типу файла.
6. Календарь / Timeline — день / неделя / месяц, drag & drop для перемещения событий между этапами (future).
7. Parser Template Builder — UI для сопоставления колонок/регулярок и тестирования на примере файла.

---

## Пайплайн загрузки и парсинга (высокоуровнево)
1. Пользователь загружает файл -> S3 (presigned или direct upload).
2. S3 событие -> Lambda/worker ставит задачу в очередь (SQS).
3. Worker берёт задачу, пытается применить подходящий ParserTemplate.
4. Если нет шаблона или шаблон не сработал — помечается требующим внимания (ради ручной правки).
5. Результат парсинга сохраняется как ParsedSnapshot и (опционально) генерируются Event'ы.
6. Для сложных файлов — отправка в LLM-парсер; результат проходит валидацию человеком.

---

## MVP backlog (разбивка на эпики/стори)
**Эпик 1: Аутентификация и организация**
- Регистрация/вход, приглашение пользователей
- RBAC, страницы организации

**Эпик 2: CRUD основных сущностей**
- Проекты, скважины, этапы, события
- UI просмотра и создания

**Эпик 3: Файловый менеджер и загрузка**
- Presigned uploads, хранение в S3, просмотр списка
- Авто-создание события "Файл загружен"

**Эпик 4: Календарь/таймлайн**
- День/неделя/месяц, отображение этапов и событий

**Эпик 5: Парсинг и шаблоны (базовый)**
- Загрузка XLSX/CSV, UI создания шаблона, парсинг и создание snapshot

**Эпик 6: LLM-парсинг и улучшения (опционально)**
- Интеграция LLM, векторизация, автопредложение шаблона

---

## Acceptance criteria (пример)
- Пользователь создаёт организацию и приглашает 1 человека — тот получает письмо и входит.
- Пользователь создаёт скважину и загружает файл — файл доступен в списке скважины < 10 секунд.
- При загрузке файла автоматически создаётся событие "Файл загружен".
- Созданный шаблон может успешно распарсить тестовый xlsx (ключевые поля присутствуют в output).

---

## Риски и замечания
- Разнообразие форматов отчётов — будет требовать большого числа шаблонов или качественного LLM-парсера.
- Хранение чувствительных данных — учесть при выборе провайдера и шифровании.
- Стоимость LLM и векторных баз — планировать бюджет.

---

## Предложение по дальнейшим шагам (оперативно)
1. Сформировать минимальный список полей, которые обязательно извлекаем из ежедневных отчётов (например: глубина, объемы закачки, параметры раствора, тип операции, начало/конец операции).
2. Создать Trello/GitHub Project — разбить MVP-эпики на стори и приоритизировать.
3. Прототип интерфейса key screens (Figma / простые wireframes).
4. Реализовать базовую загрузку файлов + S3 -> событие -> ручной парсинг для 1–2 форматов.

---

Если хочешь — могу сгенерировать сразу готовую доску Trello с эпиками/стори и примерными задачами, либо сделать минимальное ERD/схему БД и примерные модели данных (Mongo schema). Напиши, что делаем дальше.

